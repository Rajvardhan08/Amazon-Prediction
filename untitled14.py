# -*- coding: utf-8 -*-
"""Untitled14.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mfF23CeFl3qSGBypvXPKZdznLQiDY5wt
"""

import pandas as pd
import numpy as np
from haversine import haversine, Unit
import joblib
import os

def load_model_and_columns(model_path="delivery_time_model.pkl", columns_path="training_columns.pkl"):
    """Loads the trained model and the list of training columns."""
    if not os.path.exists(model_path) or not os.path.exists(columns_path):
        print("\n--- ERROR ---")
        print(f"Model file ('{model_path}') or columns file ('{columns_path}') not found.")
        print("Please make sure you have successfully run the 'train_model.py' script first,")
        print("and that these files are in the same folder as this prediction script.")
        print("-------------")
        return None, None

    print("Loading trained model and column data...")
    model = joblib.load(model_path)
    training_columns = joblib.load(columns_path)
    print("Model and columns loaded successfully.")
    return model, training_columns

def get_user_input():
    """Gets delivery details from the user via command-line input."""
    print("\n--- Enter New Delivery Details ---")
    print("Please provide the following information for the new order:")

    details = {
        'Agent_Age': float(input("Agent's Age (e.g., 35): ")),
        'Agent_Rating': float(input("Agent's Rating (e.g., 4.8): ")),
        'Store_Latitude': float(input("Store Latitude (e.g., 22.76): ")),
        'Store_Longitude': float(input("Store Longitude (e.g., 75.89): ")),
        'Drop_Latitude': float(input("Drop-off Latitude (e.g., 22.77): ")),
        'Drop_Longitude': float(input("Drop-off Longitude (e.g., 75.90): ")),
        'Order_Date': input("Order Date (YYYY-MM-DD, e.g., 2025-03-10): "),
        'Order_Time': input("Order Time (HH:MM:SS, e.g., 19:30:00): "),
        'Weather': input("Weather (e.g., Sunny, Stormy, Fog): ").strip(),
        'Traffic': input("Traffic (e.g., Low, Medium, Jam): ").strip(),
        'Vehicle': input("Vehicle type (e.g., motorcycle, scooter): ").strip(),
        'Area': input("Area type (e.g., Urban, Semi-Urban): ").strip(),
        'Category': input("Order Category (e.g., Electronics, Grocery): ").strip()
    }

    return pd.DataFrame([details])

def prepare_input_data(df, training_columns):
    """Preprocesses the user input DataFrame to match the model's training format."""
    print("Preparing input data for prediction...")

    # --- 1. Feature Engineering (same as training) ---
    df['Distance_km'] = df.apply(
        lambda row: haversine(
            (row['Store_Latitude'], row['Store_Longitude']),
            (row['Drop_Latitude'], row['Drop_Longitude']),
            unit=Unit.KILOMETERS
        ), axis=1
    )

    df['Order_Date'] = pd.to_datetime(df['Order_Date'], errors='coerce')
    df['Order_Time'] = pd.to_datetime(df['Order_Time'], errors='coerce', format='%H:%M:%S').dt.time

    df['Order_Day'] = df['Order_Date'].dt.day
    df['Order_Month'] = df['Order_Date'].dt.month
    df['Order_Day_of_Week'] = df['Order_Date'].dt.dayofweek
    df['Order_Hour'] = pd.to_datetime(df['Order_Time'].astype(str), errors='coerce').dt.hour
    df['Order_Minute'] = pd.to_datetime(df['Order_Time'].astype(str), errors='coerce').dt.minute

    # --- 2. One-Hot Encoding ---
    categorical_features = ['Weather', 'Traffic', 'Vehicle', 'Area', 'Category']
    df_encoded = pd.get_dummies(df, columns=categorical_features, dtype=int)

    # --- 3. Align Columns ---
    # This is a crucial step to ensure the prediction data has the exact same columns as the training data
    df_aligned = df_encoded.reindex(columns=training_columns, fill_value=0)

    print("Input data prepared successfully.")
    return df_aligned

def main():
    """Main function to run the prediction process."""
    model, training_columns = load_model_and_columns()

    if model and training_columns:
        input_df = get_user_input()
        prepared_df = prepare_input_data(input_df.copy(), training_columns)

        # Make the prediction
        prediction = model.predict(prepared_df)
        predicted_time = prediction[0]

        print("\n---------------------------------")
        print("      PREDICTION RESULT")
        print("---------------------------------")
        print(f"Predicted Delivery Time: {predicted_time:.0f} minutes")
        print("---------------------------------\n")

if __name__ == "__main__":
    main()

# --- Exploratory Data Analysis (EDA) & Model Development for Amazon Delivery Time Prediction ---
# This script is designed to be run in a single Google Colab cell.

# --- 1. Setup and Library Imports ---
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import files
from haversine import haversine, Unit
import warnings
import joblib

# Model Development Imports
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import mlflow

# Suppress minor warnings for cleaner output
warnings.filterwarnings('ignore')

# Set plot style for better aesthetics
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (12, 6)
print("--- Setup Complete ---")

# --- 2. Data Loading ---
# Use Google Colab's file uploader to get the dataset
print("\nPlease upload your amazon_delivery.csv file:")
uploaded = files.upload()

file_name = None
if uploaded:
    file_name = next(iter(uploaded))
    print(f"\nSuccessfully uploaded '{file_name}'.")
    df = pd.read_csv(file_name)
    print("Dataset loaded successfully.")
else:
    print("\nNo file uploaded. Halting execution.")

# --- 3. Initial Data Cleaning and Feature Engineering for Analysis ---
if file_name:
    print("\n--- Starting Initial Data Cleaning & Feature Engineering ---")
    # Basic cleaning
    df.columns = df.columns.str.strip()
    df.replace('NaN', np.nan, inplace=True)

    # Feature Engineering Part 1: Calculate distance
    if all(c in df.columns for c in ['Store_Latitude', 'Store_Longitude', 'Drop_Latitude', 'Drop_Longitude']):
        df['Distance_km'] = df.apply(
            lambda row: haversine(
                (row['Store_Latitude'], row['Store_Longitude']),
                (row['Drop_Latitude'], row['Drop_Longitude']),
                unit=Unit.KILOMETERS
            ), axis=1
        )
        print("'Distance_km' feature created.")
    else:
        print("Warning: Could not create 'Distance_km' feature due to missing location columns.")

    # Feature Engineering Part 2: Extract Time-based Features
    if 'Order_Date' in df.columns:
        df['Order_Date'] = pd.to_datetime(df['Order_Date'], errors='coerce')
        df['Order_Day_of_Week'] = df['Order_Date'].dt.day_name()
        print("'Order_Day_of_Week' feature created.")
    else:
        print("Warning: 'Order_Date' column not found. Could not create day of the week feature.")

    if 'Order_Time' in df.columns:
        df['Order_Hour'] = pd.to_datetime(df['Order_Time'].astype(str), errors='coerce').dt.hour
        print("'Order_Hour' feature created.")
    else:
        print("Warning: 'Order_Time' column not found. Could not create hour feature.")

    # Display basic info
    print("\nDataset Information:")
    df.info()

# --- 4. Key Visualizations ---
if file_name:
    print("\n\n--- Generating Key Visualizations ---")
    # (Existing EDA visualizations will be displayed here when you run the script)
    # --- 4.1 Distribution of Delivery Times ---
    print("\nDisplaying: Distribution of Delivery Times")
    plt.figure(figsize=(10, 6))
    sns.histplot(df['Delivery_Time'], bins=30, kde=True)
    plt.title('Distribution of Delivery Times (in minutes)', fontsize=16)
    plt.xlabel('Delivery Time (minutes)')
    plt.ylabel('Frequency')
    plt.show()

    # --- 4.2 Impact of Weather and Traffic on Delivery Times ---
    print("\nDisplaying: Impact of Weather and Traffic")
    fig, axes = plt.subplots(1, 2, figsize=(18, 7))
    sns.boxplot(x='Weather', y='Delivery_Time', data=df, ax=axes[0])
    axes[0].set_title('Impact of Weather on Delivery Time', fontsize=14)
    sns.boxplot(x='Traffic', y='Delivery_Time', data=df, ax=axes[1])
    axes[1].set_title('Impact of Traffic on Delivery Time', fontsize=14)
    plt.tight_layout()
    plt.show()

    # --- 4.5 Impact of Time-Based Features on Delivery Time ---
    print("\nDisplaying: Impact of Time-Based Features")
    fig, axes = plt.subplots(1, 2, figsize=(20, 7))
    if 'Order_Day_of_Week' in df.columns:
        day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
        sns.boxplot(x='Order_Day_of_Week', y='Delivery_Time', data=df, ax=axes[0], order=day_order)
        axes[0].set_title('Impact of Day of the Week on Delivery Time', fontsize=14)
    if 'Order_Hour' in df.columns:
        sns.lineplot(x='Order_Hour', y='Delivery_Time', data=df, ax=axes[1], marker='o', estimator=np.mean, errorbar=None)
        axes[1].set_title('Impact of Hour of the Day on Delivery Time', fontsize=14)
    plt.tight_layout()
    plt.show()

    # --- 4.6 Correlation Heatmap ---
    print("\nDisplaying: Correlation Heatmap of Numerical Features")
    numerical_df = df.select_dtypes(include=np.number)
    plt.figure(figsize=(12, 8))
    sns.heatmap(numerical_df.corr(), annot=True, fmt='.2f', cmap='coolwarm', linewidths=.5)
    plt.title('Correlation Heatmap of Numerical Features', fontsize=16)
    plt.show()
    print("\n--- Exploratory Data Analysis Complete ---")


# --- 5. Regression Model Development (NEW) ---
if file_name:
    print("\n\n--- Starting Regression Model Development ---")

    # --- 5.1 Preprocessing for Modeling ---
    print("\nPreprocessing data for modeling...")
    # Drop identifier, location, and original date/time columns
    model_df = df.drop(['Order_ID', 'Store_Latitude', 'Store_Longitude', 'Drop_Latitude', 'Drop_Longitude', 'Order_Date', 'Order_Time', 'Pickup_Time'], axis=1, errors='ignore')

    # Handle missing values
    for col in model_df.select_dtypes(include=np.number).columns:
        model_df[col].fillna(model_df[col].median(), inplace=True)
    for col in model_df.select_dtypes(include='object').columns:
        model_df[col].fillna(model_df[col].mode()[0], inplace=True)

    # One-Hot Encode categorical variables
    model_df = pd.get_dummies(model_df, drop_first=True, dtype=int)

    # Define features (X) and target (y)
    X = model_df.drop('Delivery_Time', axis=1)
    y = model_df['Delivery_Time']

    # Split the data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    print(f"Data split into {X_train.shape[0]} training samples and {X_test.shape[0]} testing samples.")

    # --- 5.2 Model Training and Evaluation with MLflow ---
    # Define models to train
    models = {
        'Linear Regression': LinearRegression(),
        'Random Forest Regressor': RandomForestRegressor(random_state=42),
        'Gradient Boosting Regressor': GradientBoostingRegressor(random_state=42)
    }

    results = []

    # Set the MLflow experiment
    mlflow.set_experiment("Delivery Time Prediction")

    print("\nTraining and evaluating models...")
    for model_name, model in models.items():
        with mlflow.start_run(run_name=model_name):
            # Train model
            model.fit(X_train, y_train)

            # Make predictions
            y_pred = model.predict(X_test)

            # Calculate metrics
            rmse = np.sqrt(mean_squared_error(y_test, y_pred))
            mae = mean_absolute_error(y_test, y_pred)
            r2 = r2_score(y_test, y_pred)

            # Log metrics to MLflow
            mlflow.log_metric("rmse", rmse)
            mlflow.log_metric("mae", mae)
            mlflow.log_metric("r2", r2)

            # Store results
            results.append({
                'Model': model_name,
                'RMSE': rmse,
                'MAE': mae,
                'R-squared': r2
            })
            print(f"  - {model_name} evaluated.")

    # --- 5.3 Model Comparison ---
    print("\n--- Model Comparison Results ---")
    results_df = pd.DataFrame(results).sort_values(by='R-squared', ascending=False)
    print(results_df.to_string(index=False))

    # --- 5.4 Save the Best Model (NEW) ---
    best_model_name = results_df.iloc[0]['Model']
    best_model_instance = models[best_model_name]

    print(f"\nSaving the best performing model: {best_model_name}")
    # We use the instance that was already trained on the training data
    joblib.dump(best_model_instance, 'delivery_time_model.pkl')
    joblib.dump(X.columns, 'model_columns.pkl')
    print("Model and training columns saved successfully as 'delivery_time_model.pkl' and 'model_columns.pkl'")

    print("\nTo view the MLflow UI, run 'mlflow ui' in your terminal from the correct directory.")
    print("\n--- Model Development Complete ---")

pip install mlflow

pip install haversine